\documentclass{book} 

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{float}
\usepackage{hyperref}
\usepackage{placeins}

\usepackage{tikz}
\usetikzlibrary{arrows}
\usetikzlibrary{snakes}
\usetikzlibrary{decorations.pathmorphing}

\hypersetup{
	colorlinks,
	citecolor=black,
	filecolor=black,
	linkcolor=black,
	urlcolor=black
}

\title{Solutions of Introduction to Algorithms}
\author{Saman Saadi}
\date{} 

\begin{document}
	\frontmatter
	\maketitle
%	\newpage
	\tableofcontents
	\mainmatter
	\chapter{Dynamic Programming}
	\section{Rod cutting}	
	\paragraph{Exercise 2}
	No it cannot always produce an optimal solution. Consider the following example.
	\begin{table}[H]
		\centering
		\begin{tabular}{r||c|c|c}			
			$l_i$ & 1 & 2 & 3\\
			\hline
			$p_i$ & 1 & 50 & 72 \\
			\hline
			$\frac{p_i}{l_i}$ & 1 & 25 & 24
		\end{tabular}
	\end{table}
	For n = 3 the greedy approach cut the rod in 2 pieces. The length of one of them is 2 and the other's is 1. So the profit is $50\$ + 1\$ = 51\$$. But the optimal solution is to keep the rod intact so the profit is $72\$$.
	\paragraph{Exercise 3}
	We can keep the rod intact so we don't need to incur the fixed cost c or we can have at least one cut. We need to choose the best solution among all of them:
	\begin{equation*}
	r(i) = \begin{cases}
	\max\limits_{1 \leq k < n}(p_i, r(i - k) + p_k - c) & i > 0 \\
	0 & i = 0
	\end{cases}
	\end{equation*}
	So the solution is $r(n)$. We have n distinct subproblem. In each step we need to choose between keeping the rod intact or have at least one cut which divide the rod into two pieces. The length of one of them is k and the other's $n - k$. We don't know the exact value of k so we need to try all possible values. This can be done in $O(n)$. Therefore the overall running time is $O(n^2)$
	
	\begin{algorithm}
		\begin{algorithmic}[1]
			\Function{f}{p, n, c}
			\State let r[0..n] be a new array
			\State $r[0] \gets 0$
			\For{$\text{j from 1 to n}$}
			\State $q \gets p[j]$
			\For{i from 1 to $j - 1$}
			\State $q = max(q, r[j - i] + p[i] - c)$
			\EndFor
			\State r[j] = q
			\EndFor
			\State \Return $r[n]$
			\EndFunction
		\end{algorithmic}
	\end{algorithm}
	\section{Matrix-chain multiplication}
	\paragraph{Exercise 4}
	I've used the following equations:
	\begin{align}
	\sum_{i = 1}^{n} i &= \frac{n(n + 1)}{2}\\
	\sum_{i = 1}^{n} i^2 &= \frac{n(n + 1)(2n + 1)}{6}
	\end{align}
	Each node of the graph represents a distinct sub-problem. Suppose we have two nodes v and u. There is an edge from v to u, if the solution of subproblem v is depended on subproblem u. In other words, there is an edge from m[i, j] to all m[i, k] and m[k + 1, j] for $i \le k < j$. \\
	Usually $|V|$ determines space complexity and $|V| + |E|$ time complexity. we know for every subprobelm m[i, j], $j \ge i$. Hence we have $n - i + 1$ subproblems which starts with $A_i$. So the number of vertices is:
	\begin{equation}
	\begin{split}
	|V| &= \sum_{i = 1}^{n}{n - i + 1} \\
	&= \sum_{i=1}^{n}i \\
	&= \frac{n(n + 1)}{2}
	\end{split}
	\end{equation}
	Hence the space complexity is is $O(n^2)$. We don't use all of the array cells when $j < i$. So we waste $\frac{n^2 - n}{2}$ of allocated array. By analyzing lines 5 - 10 of MATRIX-CHAIN-ORDER pseudocode in the text book we can compute the number of edges.
	\begin{figure}[h!]
	\includegraphics[width=\linewidth]{images/15/15-2-4.png}
	\end{figure}
	As you can see in line 10, m[i, j] is depends on two subproblem m[i, k] and m[k + 1, j]. We visit each distinct subproblem exactly once. So by counting the outdegree of each node we can calculate the number of edges in a directed graph:
	\begin{equation}
	\begin{split}
	|E| &= \sum_{l = 2}^{n}\sum_{i=1}^{n - l + 1}\sum_{k = i}^{i+l-2}2 \\
	&= \sum_{l=2}^{n}\sum_{i=1}^{n-l+1}2(l-1) \\
	&= 2\sum_{l=2}^{n}(n - l + 1)(l-1) \\
	&= 2\sum_{l=2}^{n}(n -(l - 1))(l-1) \\
	&= 2\sum_{l=1}^{n-1}(n-l)l \\
	&= 2(\sum_{l=1}^{n-1}nl - \sum_{l=1}^{n-1}l^2) \\
	&= 2(n\sum_{l=1}^{n-1}l - \sum_{l=1}^{n-1}l^2) \\
	&= 2[n\frac{(n - 1)n}{2} - \frac{(n - 1)(n)(2n - 1)}{6}] \\
	&= n^2(n - 1) - \frac{n(n-1)(2n-1)}{3} \\
	&= \frac{3n^2(n-1)-n(n-1)(2n-1)}{3} \\
	&= \frac{n(n-1)(3n-2n+1)}{3} \\
	&= \frac{n(n-1)(n+1)}{3}\\
	&= \frac{n(n^2-1)}{3}\\
	&= \frac{n^3 - n}{3}
	\end{split}
	\end{equation}
	So the running time is $|V| + |E| = \frac{n^2 + n}{2} + \frac{n^3 - n}{3} = O(n^3)$
	\section{Elements of dynamic programming}
	\paragraph{Exercise 2}
	Each node is filled with (p, r). p is the index of leftmost element and r is the index of rightmost element of array which the subprolem wants to sort. As you can see there is no overlapping between subproblems so dynamic programming is not a good idea for merge sort. In other words, we don't see a previously solved subproblem again and we only waste memory. As a general rule if the subproblem graph is a tree, dynamic programming cannot be applied.
	\begin{figure*}[h!]
		\centering
		\begin{tikzpicture}[level/.style={sibling distance=60mm/#1}]
		\tikzset{vertex/.style = {shape=circle,draw,scale=0.7}}
			\node[vertex] (a){$1, 16$}
				child {node[vertex] (b) {$1, 8$}
						child {node[vertex] (d) {$1, 4$}
							child {node[vertex] (h) {$1, 2$}}
							child {node[vertex] (i) {$3, 4$}}
							}
						child {node[vertex] (e) {$5, 8$}
							child {node[vertex] (j){$5, 6$}}
							child {node[vertex] (k){$7, 8$}}
							}
					}
				child {node[vertex] (c) {$9, 16$}
					child {node[vertex] (f) {$9, 12$}
						child {node[vertex] (l){$9, 10$}}
						child {node[vertex] (m){$11, 12$}}
						}
					child {node[vertex] (g) {$13, 16$}
						child {node[vertex] (n){$13, 14$}}
						child {node[vertex] (o){$15, 16$}}
						}
					}
				;
		\end{tikzpicture}
	\end{figure*}
	\chapter{Amortized Analysis}
	\section{Aggregate analysis}
	\paragraph{Exercise 1}
	No it doesn't hold. The maximum number of pops, including multipop, is proportional to the number of previous push operations. If we can only push one item, the number of pushed elements is at most $n$. If we add a new operation named multipush, then the number of pushed items is at most $n \times k$. So the amortized cost is $O(k)$. For example we can have two operations. One is multipushing $10^9$ items and the other is multipopping $10^9$ items. It is obvious the total cost is not $O(n) = O(2)$ and is $O(nk) = O(2 \times 10^9)$.
	\paragraph{Exercise 2}
	The following pseudo-code explains how to implement DECREMENT.
	\begin{algorithm*}[h!]
		\begin{algorithmic}[1]
			\Function{DECREMENT}{A}
			\State $i = 0$
			\While{$i < A.length \text{ and } A[i] == 0$}
			\State $A[i] = 1$
			\State $i = i + 1$
			\EndWhile
			\If{$i < A.length$}
			\State $A[i] = 0$
			\EndIf
			\EndFunction
		\end{algorithmic}
	\end{algorithm*}
	The worst case happens when we start with 0 and then decrements it to get $2^k - 1$ which all bits are set to 1 and then increments it to get 0. We repeat this loop until we have n operations. For $n = 4$ and $k = 3$ we have:
	\begin{align*}
		&000 \\
		&111 \\
		&000 \\
		&111
	\end{align*}
	\section{Accountant method}
	For another example of "accountant method" see exercise 5 of \ref{sec:Representation of graphs}.
	\chapter{Elementary Graph Algorithms}
	\section{Representation of graphs}
	\label{sec:Representation of graphs}
	\paragraph{Exercise 1}
	We know that $adj[u]$ is a list. Depends on the list implementation, it can take $O(1)$ to determine its size. In that case the running time for finding the out-degree of each vertex is $O(V)$. If we cannot determine size of the list in $O(1)$, then the overall running time of algorithm is $O(V + E)$. \\
	The running time for finding in-degree of each vertex is $O(V + E)$.
	\paragraph{Exercise 3}
	For adjacency-matrix it takes $O(V^2)$ and for adjacency-list it takes $O(V + E)$.
	\begin{algorithm}[h!]
		\caption{$G'$ using adjacency matrix}
		\begin{algorithmic}[1]
			\Function{TransposeGraph}{G}
				\State Let $G'$ be a new graph
				\State $G' \gets G$
				\ForAll{$u \in V$}
					\ForAll{$v \in V$}
						\State $G'.A[v][u] = G.A[u][v]$
					\EndFor
				\EndFor
				\State \Return $G'$
			\EndFunction
		\end{algorithmic}
	\end{algorithm}
	\begin{algorithm*}[h!]
		\caption{$G'$ using adjacency list}
		\begin{algorithmic}[1]
			\Function{TransposeGraph}{G}
				\State Let $G'$ be a new graph
				\State $G'.V = G.V$
				\ForAll{$u \in G.V$}
					\ForAll{$v \in G.Adj[u]$}
						\State $G'.Adj[v].insert(u)$
					\EndFor
				\EndFor
			\EndFunction
		\end{algorithmic}
	\end{algorithm*}
	\FloatBarrier
	\paragraph{Exercise 4}
	We create a new adjacency-list for $G'$ called $adj$. For each vertex $u$ in $G$, suppose $v$ is its neighbor. If $u \ne v$, then $adj[u].insert(v)$ and $adj[v].insert(u)$. If there are multiple edges between $u$ and $v$, we see $v$ as $u$'s neighbor more than once. So if the last element if $adj[v]$ is $u$, it means there are more than one edges between them so we shouldn't insert $v$ again. Traversing $G$ takes $O(V + E)$. Finding out there are more than one edge between two vertices is $O(1)$. So the overall running time is $O(V + E)$. Note that I supposed $G$ is also undirected.
	\begin{algorithm}[h!]
		\begin{algorithmic}[1]
			\Function{f}{G}
			\State $\text{let }G' \text{ be a new graph}$
			\State $G'.V = G.V$
			\ForAll{$u \in G.V$}
				\ForAll{$v \in G.adj[u]$}
					\If{$u \ne v \land G'.adj[v].last() \ne u$}
						\State $G'.adj[v].insert(u)$		
					\EndIf
				\EndFor
			\EndFor
			\State \Return $G'$
			\EndFunction
		\end{algorithmic}
	\end{algorithm}
	\paragraph{Exercise 5}
	The running time of matrix-list implementation is $O(V^3)$. For analyzing the running time of adjacency-list implementation we can use amortized analysis. We use "accountant method".
	\begin{enumerate}
		\item[] $\boldsymbol{in_u:}$ The number of edges that enter $u$
		\item[] $\boldsymbol{out_u:}$ The number of edges that leave $u$
		\item[] $\boldsymbol{e_u:}$ And edge from u to an arbitrary vertex $v \ne u$
	\end{enumerate}
	We assign to all $e_u$ cost $c_{e_u} = 1 + in_u$. Because by traversing the graph, we visit $e_u$ at least once (line \ref{MakeSquareGraph:1-path}). For each edge that enters $u$ we visit or revisit $e_u$ (lines \ref{MakeSquareGraph:2-path:1} - \ref{MakeSquareGraph:2-path:2}). We know that $\sum_{u = 1}^{|V|}{in_u} + \sum_{u = 1}^{|V|}{out_u} = 2|E|$. So we can easily calculate the total cost.
	\begin{equation*}
		\begin{split}
		\sum_{e_u \in E}{c_{e_u}} &= \sum_{e_u \in E}{1 + in_u} \\
		&= \sum_{e_u \in E}{1} + \sum_{u = 1}^{|V|}{in_u} \\
		&= |E| + \sum_{u = 1}^{|V|}{in_u} \\
		&\le 3|E|
		\end{split}
	\end{equation*}
	We execute line \ref{MakeSquareGraph:1-path} at most $|E|$ times and lines \ref{MakeSquareGraph:2-path:1} - \ref{MakeSquareGraph:2-path:2} at most $2|E|$ times. So the total running time of algorithm using adjacency-list is $O(|V| + 3|E|) = O(V + E)$.
	\begin{algorithm*}[h!]
		\caption{Finding square graph using matrix-list}
		\begin{algorithmic}[1]
			\Function{MakeSquareGraph}{G}
				\State Let $G'$ be a new Graph
				\Comment $G.A[1..|V|, 1..|V|]$
				\ForAll{$u \in G.V$}
					\ForAll{$v \in G.V$}
						\State $G'.A[u][v] = G.A[u][v]$
						\Comment 1-edge paths
						\If{$G.A[u][v] = 1$}
							\ForAll{$k \in G.V$}
								\State $G'.A[u][k] = G.A[v][k]$
								\Comment 2-edge paths
							\EndFor
						\EndIf
					\EndFor
				\EndFor				
			\EndFunction
		\end{algorithmic}
	\end{algorithm*}
	\begin{algorithm*}[h!]
		\caption{Finding square graph using adjacency-list}
		\begin{algorithmic}[1]
			\Function{MakeSqureGraph}{G}
				\State Let $G'$	be a new graph
				\State $G'.V = G.V$
				\ForAll{$u \in G.V$}
					\ForAll{$v \in G.Adj[u]$}
						\State $G'.Adj[u].insert(v)$ \label{MakeSquareGraph:1-path}
						\Comment 1-edge paths
						\ForAll{$w \in G.Adj[v]$} \label{MakeSquareGraph:2-path:1}
							\State $G'.Adj[u].insert(w)$ \label{MakeSquareGraph:2-path:2}
							\Comment 2-edge paths
						\EndFor						
					\EndFor
				\EndFor
			\EndFunction
		\end{algorithmic}
	\end{algorithm*}
	\FloatBarrier
	\paragraph{Exercise 6}
	Suppose $A$ is an adjacency matrix for $G$.
	\begin{equation*}
		A[i, j] = \begin{cases}
		1 & \text{i cannot be a universal sink} \\
		0 & \text{j cannot be a universal sink}
		\end{cases}
	\end{equation*}
	The following algorithm find the universal sink in $O(V)$. In each step we remove one vertex from all candidates for "universal sink". It takes $O(V)$ to have only one candidate. To determine that candidate is indeed a universal sink we need $O(2V)$ operations. So the overall running time of algorithm is $O(V) + O(2V) = O(V)$.
	\begin{algorithm*}[h!]
		\begin{algorithmic}[1]
			\Function{getUniversalSink}{G}
				\State $A = G.A$
				\Comment $A[1..|V|, 1..|V|]$
				\State $u \gets 1$								
				\While{$u \le |V|$}
					\State $v \gets u + 1$
					\State $sink \gets u$
					\Comment Vertices from $sink$ to $|V|$ can be universal sink					
					\While{$v \le |V| \land A[u, v] = 0$}
						\State $v \gets v + 1$
						\Comment $v$ cannot be a universal sink
					\EndWhile
					\State $u \gets v$
					\Comment $u$ to $v - 1$ cannot be a universal sink
				\EndWhile
				\For{$c$ from $1$ to $sink - 1$}
					\If{$A[sink, c] \ne 0$}
						\State \Return "No universal sink"
					\EndIf
				\EndFor
				\For{$r \in V - \{sink\}$}
					\If{$A[r, sink] \ne 1$}
						\State \Return "No universal sink"
					\EndIf
				\EndFor
				\State \Return sink
			\EndFunction
		\end{algorithmic}
	\end{algorithm*}
	\FloatBarrier
	\paragraph{Exercise 7}
	We know that $B$ is an $V \times E$ matrix which we show it as $B_{V \times E}$. By definition $B^T$ is an $E \times V$ matrix which we show it as $B_{E \times V}^T$. We define $P_{V \times V} = B_{V \times E} \times B_{E \times V}^T$.
	\begin{equation*}
		p[i, j] = \sum_{k = 1}^{E}b[i, k] \times b^T[k, j]
	\end{equation*}
	We consider two cases.
	\begin{enumerate}
		\item $\boldsymbol{i \ne j:}$ It is impossible that both $b[i, k]$ and $b[k, j]$ have the value of "1". Because the k\textsuperscript{th} edge cannot enter both vertices $i$ and $j$. With the same argument we can prove that both of them cannot have value of "-1". If the k\textsuperscript{th} edge connect i to j, then $b[i, k] = -1$ and $b^T[k, j] = 1$. Otherwise both have value of zero. In other words, for $i \ne j$ the value of $p[i, j]$ is the number of edges between $i$ and $j$.
		\item $\boldsymbol{i = j:}$ It is obvious both $b[i, k]$ and $b[k, i]$ should have the same value. In this case $p[i, i]$ is the sum of all edges that enter and leave the vertex $i$.
	\end{enumerate}
	\begin{equation*}
		p[i, j] = \begin{cases}
		\text{number of edges between i and j} & i \ne j \\
		indegree(i) + outdegree(i) & i = j
		\end{cases}
	\end{equation*}
	\section{Breadth-first search}
	\paragraph{Exercise 7}
	We need to determine whether an undirected graph is bipartite or not. We can paint the vertices of a bipartite graph with two colors in such a way that no two adjacent vertices share the same color.\\
	We can easily prove that if there is a cycle in graph in which the number of edges is odd, then the graph cannot be bipartite. \\
	We can use BFS. We know that in an undirected graph we can only have tree and back edges (see \ref{psec:EdgeClassification}). We run BFS on an arbitrary vertex $s$. Suppose $u$ is reachable from $s$. If $u.d$ is even we color that vertex "blue" otherwise we color it "red". For tree edges we don't have any problem. We need to think about back edges. \\
	Suppose $(u, v)$ is a back edge. Since we discover $v$ first we can say $v.d \le u.d$. We know that $(v, u)$ is also an edge. According to BFS properties $u.d \le v.d + 1$. Hence $0 \le u.d - v.d \le 1$. If $u.d = v.d + 1$, then $u$ and $v$ have different colors. So we only need to consider $u.d = v.d$. In that case both $u$ and $v$ have the same color and we need to prove that this graph cannot be bipartite. When we have a back edge it means that we have a cycle. The number of edges in this cycle is $u.d + v.d + 1 = 2 \times u.d + 1$ which is odd. So the graph cannot be bipartite. Note that the graph can have more than one connected component so it is possible we need to run BFS more than once. We use a new attribute $u.bColor$ which we use for bipartite color as described.
	\begin{algorithm*}[h!]
		\caption{Determining whether a graph is bipartite or not}
		\begin{algorithmic}[1]
			\Function{IsBipartiteGraph}{G}
				\ForAll{$u \in G.V$}
					\State $u.color = WHITE$
					\State $u.d = \infty$
					\State $u.\pi = NIL$
				\EndFor
				\ForAll{$u \in G.V$}
					\If{$u.color == WHITE\text{ }\land$ \Call{BFS}{G, u}$\text{ } == FALSE$}
						\State \Return $FALSE$
					\EndIf
				\EndFor	
				\State \Return $TRUE$
			\EndFunction		
		\end{algorithmic}
		\begin{algorithmic}
			\Statex
		\end{algorithmic}
		\begin{algorithmic}[1]		
			\Function{BFS}{G, s}
				\State $s.color = GRAY$
				\State $s.bColor = 0$ \Comment The color which we use for bipartite algorithm
				\State $s.d = 0$
				\State $Q = \emptyset$
				\State \Call{Enqueue}{Q, s}
				\While{$Q \ne \emptyset$}
					\State $u = $ \Call{Dequeue}{Q}
					\ForAll{$v \in G.adj[u]$}
						\If{$v.color == WHITE$} \Comment edge $(u, v)$ is a tree edge
							\State $v.color = GRAY$
							\State $v.bColor = 1 - u.bColor$
							\State $v.d = u.d + 1$
							\State $v.\pi = u$
							\State \Call{Enqueue}{Q, v}
						\ElsIf{u.bColor == v.bColor} \Comment edge $(u, v)$ is a back edge
							\State \Return $FALSE$
						\EndIf
					\EndFor
					\State $u.color = BLACK$
				\EndWhile
				\State \Return $TRUE$
			\EndFunction
		\end{algorithmic}				
	\end{algorithm*}
	\FloatBarrier
	\paragraph{Exercise 8}
	It is easy to prove that the first and last vertex of the diameter is a leaf. Choose an arbitrary vertex $s$ and perform BFS on the graph. The vertex that has maximum number of edges from $s$ is one of the diameter's endpoints which we call it $u$. Then run another BFS from $u$ to get vertex $v$ which has maximum number of edges from $u$. This is the diameter.
	\paragraph{exercise 9}
	This undirected graph is equivalent to a directed graph which for all $u, v \in V$, $(u, v), (v, u) \in E$. We can use a modified version of DFS. Because we have both edges $(u, v)$ and $(v, u)$, we don't have "cross edges". We need to choose between "forward edges" or "back edges". In the following algorithm we use "forward edges" and skip "back edges".
	\begin{algorithm*}
		\begin{algorithmic}[1]
			\Function{DFS}{G, u}
				\State $u.color \gets Gray$
				\State $paths \gets \phi$
				\ForAll{$v \in G.Adj[u]$}
					\If{$v.color = White$} \Comment{Tree edge}
						\State $paths \gets \{(u, v)\} \cup DFS(G, v) \cup \{(v, u)\}$
					\ElsIf{$v.color = Black$} \Comment{Forward edge}
						\State $paths \gets paths \cup \{u, v\} \cup \{v, u\}$
					\EndIf
				\EndFor
				\State $u.color \gets Black$
				\State \Return paths
			\EndFunction
		\end{algorithmic}
	\end{algorithm*}
	\FloatBarrier
	\section{Depth-first search}
	\phantomsection
	\label{psec:EdgeClassification}
	\paragraph{Edge classification}
	Suppose $s$ is the root of DFS or BFS tree.
	\begin{itemize}
		\item \textbf{Tree edge}
		\begin{itemize}
			\item Directed graph
			\begin{itemize}
				\item DFS: We can have tree edges
				\item BFS: We can have tree edges
			\end{itemize}
			\item Undirected graph
			\begin{itemize}
				\item DFS: We can have tree edges
				\item BFS: We can have tree edges
			\end{itemize}				
		\end{itemize}
		\item \textbf{Forward edge}
		\begin{itemize}
			\item Directed graph
			\begin{itemize}
				\item DFS: We can have forward edges
				\item BFS: We can't have forward edges. Suppose we can have forward edge $(u, v)$. According to forward edge properties we can say $u.d < v.d$ (if $u.d = v.d$ it's cross edge) and according to BFS properties $v.d \le u.d + 1$. Hence $0 < v.d - u.d \le 1$. If $v.d = u.d + 1$ it is a tree edge, unless we have a multigraph. So $(u, v)$ cannot be a forward edge.
			\end{itemize}
			\item Undirected graph
			\begin{itemize}
				\item DFS: We can't have forward edges
				\item BFS: We can't have forward edges
			\end{itemize}				
		\end{itemize}
		\item \textbf{Back edge}
		\begin{itemize}
			\item Directed graph
			\begin{itemize}
				\item DFS: We can have back edges
				\item BFS: We can have back edges. Suppose $(u, v)$ is a back edge. Since we discover $v$ first we can say $v.d \le u.d$. According to BFS properties we can say $v.d \le u.d + 1$. Hence $v.d -u.d \le 1$. Note that we have only upper bound. So it is possible $v.d - u.d < 0$
			\end{itemize}
			\item Undirected graph
			\begin{itemize}
				\item DFS: We can have back edges
				\item BFS: We can have back edges. Suppose $(u, v)$ is a back edge. Since we discover $v$ first we can say $v.d \le u.d$. We know that $(v, u)$ is also an edge. According to BFS properties $u.d \le v.d + 1$. Hence $0 \le u.d - v.d \le 1$
			\end{itemize}
		\end{itemize}
		\item \textbf{Cross edge}
		\begin{itemize}
			\item Directed graph
			\begin{itemize}
				\item DFS: We can have cross edges
				\item BFS: We can have cross edges. Suppose $(u, v)$ is a cross edge. Since we discover $v$ first we can say $v.d \le u.d$. According to BFS properties we can say $v.d \le u.d + 1$. Hence $v.d - u.d \le 1$. Note that we only have upper bound. It is possible that $v.d - u.d < 0$. See figure \ref{fig:BfsCrossEdgeDirectedGraph}
			\end{itemize}
			\item Undirected graph
			\begin{itemize}
				\item DFS: We can't have cross edges
				\item BFS: We can't have cross edges
			\end{itemize}
		\end{itemize}		
	\end{itemize}
	\begin{figure*}[h!]
		\centering
		\caption{BFS -- cross edge in a directed graph. $v.d \le u.d + 1$}
		\label{fig:BfsCrossEdgeDirectedGraph}
		\begin{tikzpicture}
		\tikzset{vertex/.style={shape = circle, draw, minimum size = 1.5em}}
		\tikzset{edge/.style={->, > = latex'}}
		\tikzset{snake it/.style={-stealth,
				decoration={snake, 
					amplitude = 1mm,
					segment length = 8mm,
					post length=0.9mm},decorate}}
		%vertices
		\node[vertex] (s) at (0, 2) {$s$};
		\node[vertex] (w) at (0, 0) {$w$};
		\node[vertex] (u) at (0, -2) {$u$};
		\node[vertex] (v) at (-1, -1) {$v$};
		%edges
		\path[edge] (s) edge[snake it] node[midway, above, rotate=-90]{$T$} (w);
		\path[edge] (w) edge[snake it, bend left] node[midway, above, rotate=-45]{$T$} (u);
		\draw[edge] (w) -- (v) node[midway, above, rotate=45]{$T$};
		\draw[edge] (u) -- (v) node[midway, above, rotate=-45]{$C$};
		\end{tikzpicture}
	\end{figure*}
	\FloatBarrier	
	\paragraph{Exercise 1}
	You can use the following facts. Suppose we have edge (u, v) and we consider loops as back edges.
	\begin{align*}	
	\begin{split}
		\text{\textbf{Tree edge: }} u.d &< v.d < v.f < u.f \\
		\text{\textbf{Forward edge: }} u.d &< v.d < v.f < u.f \\
		\text{\textbf{Back edge: }} v.d &\le u.d < u.f \le v.f \\
		\text{\textbf{Cross edge: }} v.d &< v.f < u.d < u.f \\
	\end{split}
	\end{align*}
	Note that when the graph is undirected we don't have "forward edge" and "cross edge". Because they are equivalent to "back edge" and "tree edge" respectively.
	\begin{table*}[h!]
		\centering
		\caption{Directed graph}
		\begin{tabular}{r|c|c|c}
			& white & gray & black \\
			\hline
			white & tree, back, forward, cross & back, cross & cross \\
			\hline
			gray & tree, forward  & tree, back, forward & tree, forward, cross \\
			\hline
			black & impossible & back & tree, back, forward, cross \\
		\end{tabular}
	\end{table*}
	\begin{table*}[h!]
		\centering
		\caption{Undirected graph}
		\begin{tabular}{r|c|c|c}
			& white & gray & black \\
			\hline
			white & tree, back & tree, back & impossible \\
			\hline
			gray & tree, back & tree, back & tree, back\\
			\hline
			black & impossible & tree, back & tree, back \\
		\end{tabular}
	\end{table*}
	\FloatBarrier
	\paragraph{Excercise 8}
	We need to show some examples which there is only one path from $u$ to $v$ and at least of one the edges in this path is non-tree edge. Without loss of generality, suppose in this path except $e = (w, x)$ which is a non-tree edge, all other edges are tree ones. We consider all possible types.
	\begin{figure*}[h!]
		\centering
		\caption{Edge e = (w, x) is a non-tree edge}
		\begin{tikzpicture}
			\tikzset{vertex/.style={shape = circle, draw, minimum size = 1.5em}}
			\tikzset{edge/.style={->, > = latex'}}
		\tikzset{snake it/.style={-stealth,
				decoration={snake, 
					amplitude = 1mm,
					segment length = 8mm,
					post length=0.9mm},decorate}}
			%vertices
			\node[vertex] (u) at (0, 0) {$u$};
			\node[vertex] (w) at (4, 0) {$w$};
			\node[vertex] (x) at (6, 0) {$x$};
			\node[vertex] (v) at (10, 0) {$v$};
			%edges
			\path[edge] (u) edge[snake it] node[midway, above]{$T$} (w);
			\draw[edge] (w) -- (x) node[midway, above]{$\ne T$};
			\path[edge] (x) edge[snake it] node[midway, above]{$T$} (v);
		\end{tikzpicture}
	\end{figure*}
	\begin{itemize}
		\item \textbf{Forward Edge:} If $(w, x)$ is forward ege, then $w$ is an ancestor of $x$ which leads to $v$ be a descendant of $u$. So it cannot be a forward edge
		\item \textbf{Cross edge:} If $(w, x)$ is a cross edge, then $x$ finishes before the discovery of $w$. In other words, all reachable vertices from $x$, including $v$, will be discover before $w$ and $u$. So it cannot be a cross edge
		\item \textbf{Back edge:} Consider the following example which the root of DFS tree is vertex $x$ and it discover $u$ before $v$.
	\begin{figure*}[h!]
		\centering
		\caption{Counterexample using back edge}
		\begin{tikzpicture}
		\tikzset{vertex/.style={shape = circle, draw, minimum size = 1.5em}}
		\tikzset{edge/.style={->, > = latex'}}
		\tikzset{snake it/.style={-stealth,
				decoration={snake, 
					amplitude = 1mm,
					segment length = 8mm,
					post length=0.9mm},decorate}}			
					%vertices
					\node[vertex] (s) at (6, 0) {$x$};
					\node[vertex] (u) at (0, 0) {$u$};
					\node[vertex] (w) at (4, 0) {$w$};
					\node[vertex] (v) at (10, 0) {$v$};
					%edges
					\path[edge] (s) edge[snake it, bend left] node[midway, above] {T} (u);
					\path[edge] (u) edge[snake it] node[midway, above] {T} (w);
					\draw[edge] (w) -- (s) node[midway, above]{B};
					\path[edge] (s) edge[snake it] node[midway, above]{T}(v);
					
					\end{tikzpicture}
					\end{figure*}		
	\end{itemize}
	\FloatBarrier
	\paragraph{Excercise 9}
	Suppose we have edge (u, v) and we consider loops as back edges.
	\begin{align*}	
	\begin{split}
	\text{\textbf{Tree edge: }} u.d &< v.d < v.f < u.f \\
	\text{\textbf{Forward edge: }} u.d &< v.d < v.f < u.f \\
	\text{\textbf{Back edge: }} v.d &\le u.d < u.f \le v.f \\
	\text{\textbf{Cross edge: }} v.d &< v.f < u.d < u.f \\
	\end{split}
	\end{align*}
	As you can see only in cross edge the discovery of one endpoint is after the other finished. We need to prove that if there is a path from $u$ to $v$, it is possible to have $v.d > u.f$. In other words, edge $(v, u)$ is a cross edge and there is a path from $u$ to $v$ in which there is at least one edge which is not a tree edge. We can make counterexample even simpler by removing the cross edge. Note that the root of DFS tree is vertex $s$. In general if there is a cycle from $s$ to $u$ and $u$ to $s$, then it is possible $v.d > u.f$.
	
	\begin{figure*}[h!]
		\centering
		\caption{Counterexample using cross edge}
		\begin{tikzpicture}
			\tikzset{vertex/.style = {shape=circle,draw,minimum size=1.5em}}
			\tikzset{edge/.style = {->,> = latex'}}
			% vertices
			\node[vertex] (s) at (0, 0) {$s$};
			\node[vertex] (u) at (2, -2) {$u$};
			\node[vertex] (v) at (-2, -2) {$v$};
			% edges
			\draw[edge] (s) -- (u) node[midway, above, rotate=-45] {T};
			\draw[edge] (v) -- (u) node[midway, above] {C};
			\draw[edge] (s) -- (v) node[midway, above, rotate=45] {T};
			\draw[edge] (u) edge[bend right] node [midway, above, rotate=-45] {B} (s);
		\end{tikzpicture}		
	\end{figure*}
	\begin{figure*}[h!]
		\centering
		\caption{Counterexample without cross edge}
		\begin{tikzpicture}
		\tikzset{vertex/.style = {shape=circle,draw,minimum size=1.5em}}
		\tikzset{edge/.style = {->,> = latex'}}
		% vertices
		\node[vertex] (s) at (0, 0) {$s$};
		\node[vertex] (u) at (2, -2) {$u$};
		\node[vertex] (v) at (-2, -2) {$v$};
		% edges
		\draw[edge] (s) -- (u) node[midway, above, rotate=-45] {T};
		\draw[edge] (s) -- (v) node[midway, above, rotate=45] {T};
		\draw[edge] (u) edge[bend right] node [midway, above, rotate=-45] {B} (s);				
		\end{tikzpicture}		
	\end{figure*}
	\begin{figure*}[h!]
		\centering
		\caption{General counterexample}
		\begin{tikzpicture}
		\tikzset{vertex/.style = {shape=circle,draw,minimum size=1.5em}}
		\tikzset{edge/.style = {->,> = latex'}}
		\tikzset{snake it/.style={-stealth,
				decoration={snake, 
					amplitude = .4mm,
					segment length = 2mm,
					post length=0.9mm},decorate}}			
		% vertices
		\node[vertex] (s) at (0, 0) {$s$};
		\node[vertex] (u) at (2, -2) {$u$};
		\node[vertex] (v) at (-2, -2) {$v$};
		% edges
		\path[edge] (s) edge[bend left, snake it] (u);
		\path[edge] (s) edge[snake it] (v);
		\path[edge] (u) edge[bend left, snake it](s);				
		\end{tikzpicture}		
	\end{figure*}		
	\FloatBarrier
	\paragraph{Exercise 10}
	In an undirected graph forward edges are equivalent to back edges and cross edges are equivalent to tree edges. Although the following modification works for both directed and undirected graph, you can remove portion of code that is related to "forward" and "cross" edges to save space.
	\begin{algorithm*}
		\begin{algorithmic}[1]
			\Function {DFS-VISIT}{G, u}
				\State $time = time + 1$
				\State $u.d = time$
				\State $u.color = GRAY$
				\ForAll{$v \in G.adj[u]$}
					\If{$v.color == WHITE$} \Comment edge $(u, v)$ is a tree edge
						\State \Call{PRINT-EDGE}{u, v, TREE}
						\State $v.\pi = u$
						\State \Call{DFS-VISIT}{$G, v$}
					\ElsIf{$v.color == GRAY$} \Comment edge $u, v$ is a back edge
						\State \Call{PRINT-EDGE}{u, v, BACK}
					\ElsIf{$u.d < v.d$}
						\State \Call{PRINT-EDGE}{u, v, FORWARD}
					\Else
						\State \Call{PRINT-EDGE}{u, v, CROSS}
					\EndIf
				\EndFor
				\State $u.color = BLACK$
				\State $time = time + 1$
				\State $u.f = time$
			\EndFunction
		\end{algorithmic}
	\end{algorithm*}
	\paragraph{Exercise 11}
	If both incoming and outgoing edges are cross, that happens. Consider the following example. Suppose DFS starts at $s$, then $u$ and finally at $w$.
	\begin{figure*}[h!]
		\begin{tikzpicture}
			\tikzset{vertex/.style = {shape=circle,draw,minimum size=1.5em}}
			\tikzset{edge/.style = {->,> = latex'}}
			% vertices
			\node[vertex] (s) at (0, 0) {$s$};
			\node[vertex] (n) at (-1, -1) {$n$};
			\node[vertex] (u) at (1, -1) {$u$};
			\node[vertex] (w) at (2, 0) {$w$};
			% edges
			\draw[edge] (s) -- (n) node[midway, above, rotate=45] {T};
			\draw[edge] (u) -- (s) node[midway, above, rotate=-45] {C};
			\draw[edge] (w) -- (u) node[midway, above, rotate=45] {C};
		\end{tikzpicture}
	\end{figure*}
	\FloatBarrier
	\paragraph{Exercise 12}
	There exists at least one path between every two vertices in a connected component. So if we perform DFS on an arbitrary vertex $u$, it will discover all reachable vertices from $u$. After DFS visit all vertices in $u$'s connected component it terminates. So the number of DFS trees is equal to the number of connect components in undirected graph. This is not true for directed graphs. Consider figure \ref{fig:NonSinglyConnectedGraph}. If we start from $u$ we only have one DFS tree. But if we start from $v$, $x_1$, $x_2$, $x_3$, $x_4$ and finally $u$, the number of DFS trees are equal to the number of vertices. In other words, all DFS trees are consist of only a vertex and we don't have any tree edges.
	
	\begin{algorithm}[h!]
		\caption{Connected components in an undirected graph}
		\begin{algorithmic}[1]
			\Function{DFS}{G}
				\ForAll{$u \in G.V$}
					\State $u.color = WHITE$
					\State $u.\pi = NIL$
				\EndFor
				\State $time = 0$
				\State $ccn = 0$ \Comment $ccn$ is the number of connected components
				\ForAll{$u \in G.V$}
					\If{u.color == WHITE}
						\State $ccn = ccn + 1$					
						\State \Call{DFS-VISIT}{G, u}
					\EndIf
				\EndFor
			\EndFunction
		\end{algorithmic}
		\begin{algorithmic}
			\Statex
		\end{algorithmic}	
		\begin{algorithmic}[1]
			\Function {DFS-VISIT}{G, u}
			\State $time = time + 1$
			\State $u.d = time$
			\State $u.cc = ccn$
			\State $u.color = GRAY$
			\ForAll{$v \in G.adj[u]$}
			\If{$v.color == WHITE$}
			\State $v.\pi = u$
			\State \Call{DFS-VISIT}{$G, v$}
			\EndIf
			\EndFor
			\State $u.color = BLACK$
			\State $time = time + 1$
			\State $u.f = time$
			\EndFunction			
		\end{algorithmic}
	\end{algorithm}
	\FloatBarrier
	\paragraph{Exercise 13}
	It is obvious that we should only have tree and back edges. It is important to start from the right vertex. Consider figure \ref{fig:NonSinglyConnectedGraph}. There is exactly two distinct paths between $u$ and $v$. If we start the DFS from $u$, in the first run we can detect that the graph is not singly connected.
	\begin{figure}[h!]
		\centering
		\caption{non singly connected graph}
		\label{fig:NonSinglyConnectedGraph}		
		\begin{tikzpicture}
		\tikzset{vertex/.style={shape = circle, draw, minimum size = 1.5em}}
		\tikzset{edge/.style={->, > = latex'}}
		\tikzset{snake it/.style={-stealth,
				decoration={snake, 
					amplitude = 1mm,
					segment length = 8mm,
					post length=0.9mm},decorate}}
		%vertices
		\node[vertex] (u) at (0, 0) {$u$};
		\node[vertex] (x3) at (1, 1) {$x_3$};
		\node[vertex] (x4) at (1, -1) {$x_4$};
		\node[vertex] (x1) at (3, 1) {$x_1$};
		\node[vertex] (x2) at (3, -1) {$x_2$};
		\node[vertex] (v) at (4, 0) {$v$};
		%edges
		\draw[edge] (u) -- (x3);
		\draw[edge] (u) -- (x4);
		\draw[edge] (x3) -- (x1);
		\draw[edge] (x4) -- (x2);
		\draw[edge] (x1) -- (v);
		\draw[edge] (x2) -- (v);
		\end{tikzpicture}
	\end{figure}
	I thought I can design an $O(V + E)$ algorithm to solve this problem. I was wrong.
	\subparagraph{Wrong idea}
	Start DFS from an arbitrary vertex $s$. If you found "forward" or "cross" edges then it is not singly connected so the algorithm terminates. After DFS finished, it is possible we have unvisited vertices.
	\begin{itemize}
		\item[] \textbf{component:} All undiscovered vertices which will be discover in one DFS run. For example if we run DFS from $x_3$ in figure \ref{fig:NonSinglyConnectedGraph}, $x_3$, $x_1$ and $u$ are belong to the same component.
	\end{itemize}
	We can determine and number the components (similar to connected components). If we find "forward" or "cross" edges within each component, the algorithm terminates. Note that "cross" edges between components is not trivial. We can have singly connected graph which has at least one cross edge between its components. We can create a new graph which its vertices are the components of input graph and its edges are the cross edges between components. Suppose in figure \ref{fig:NonSinglyConnectedGraph} we run DFS first on $x_3$, then $x_4$ and finally $u$. You can see the result in figure \ref{fig:GraphOfComponents}. This algorithm is not always correct. Suppose we run DFS first on $v$, $x_1$, $x_2$, $x_3$, $x_4$ and finally $u$. As you can see we don't have any tree edges and the graph of components is same as original one.
	\begin{figure}[h!]
		\centering
		\caption{Graph of components}
		\label{fig:GraphOfComponents}
		\begin{tikzpicture}
		\tikzset{vertex/.style={shape = circle, draw, minimum size = 1.5em}}
		\tikzset{edge/.style={->, > = latex'}}
		\tikzset{snake it/.style={-stealth,
				decoration={snake, 
					amplitude = 1mm,
					segment length = 8mm,
					post length=0.9mm},decorate}}
		%vertices
		\node[vertex] (u) at (0, 0) {$u$};
		\node[vertex] (x4) at (2, -2) {$x_4, x_2$};
		\node[vertex] (v) at (4, 0) {$x_3, x_1, v$};
		%edges
		\draw[edge] (u) -- (v);
		\draw[edge] (u) -- (x4);
		\draw[edge] (x4) -- (v);
		\end{tikzpicture}
	\end{figure}	
\end{document}
